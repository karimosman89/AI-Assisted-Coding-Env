# üéØ AI-Assisted Coding Environment Examples

This directory contains comprehensive examples demonstrating the powerful capabilities of the AI-Assisted Coding Environment. Each example includes practical use cases, code samples, and step-by-step guides.

## üìÅ Directory Structure

```
examples/
‚îú‚îÄ‚îÄ api_usage/              # API integration examples
‚îú‚îÄ‚îÄ collaboration/          # Real-time collaboration demos
‚îú‚îÄ‚îÄ ai_workflows/          # AI-powered development workflows
‚îú‚îÄ‚îÄ integrations/          # Third-party service integrations
‚îú‚îÄ‚îÄ deployment/            # Deployment configurations
‚îú‚îÄ‚îÄ extensions/            # Custom extensions and plugins
‚îî‚îÄ‚îÄ tutorials/             # Step-by-step learning guides
```

## üöÄ Quick Start Examples

### 1. Basic API Usage

#### Generate Python Function
```python
import requests
import json

# Configure API endpoint
API_BASE = "http://localhost:8000/api"
headers = {"Content-Type": "application/json"}

# Generate a sorting function
response = requests.post(
    f"{API_BASE}/ai/generate",
    headers=headers,
    json={
        "description": "Create a quicksort function with detailed comments",
        "language": "python",
        "context": {
            "style": "educational",
            "include_tests": True
        }
    }
)

result = response.json()
if result["success"]:
    print("Generated Code:")
    print(result["content"])
else:
    print("Error:", result["error"])
```

#### Analyze Code Quality
```python
code_to_analyze = """
def fibonacci(n):
    if n <= 1:
        return n
    else:
        return fibonacci(n-1) + fibonacci(n-2)

print(fibonacci(30))
"""

response = requests.post(
    f"{API_BASE}/ai/analyze",
    headers=headers,
    json={
        "content": code_to_analyze,
        "language": "python",
        "analysis_type": "comprehensive",
        "include_suggestions": True
    }
)

analysis = response.json()
print("Code Analysis:")
print(analysis["content"])
```

### 2. WebSocket Real-Time Features

#### Real-Time Code Completion
```javascript
// Connect to WebSocket
const ws = new WebSocket('ws://localhost:8000/ws/coding/my_client_id');

ws.onopen = function() {
    console.log('Connected to AI Assistant');
    
    // Request code completion
    ws.send(JSON.stringify({
        type: 'ai_complete',
        data: {
            content: 'def calculate_fibonacci(',
            language: 'python'
        }
    }));
};

ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    
    if (message.type === 'ai_completion_result') {
        console.log('AI Suggestion:', message.data.content);
        // Insert completion into editor
        insertCompletion(message.data.content);
    }
};

function insertCompletion(completion) {
    // Monaco Editor integration
    const editor = monaco.editor.getModels()[0];
    const position = editor.getPosition();
    
    editor.executeEdits('ai-completion', [{
        range: new monaco.Range(
            position.lineNumber, 
            position.column,
            position.lineNumber, 
            position.column
        ),
        text: completion
    }]);
}
```

#### Live Collaboration
```javascript
// Join a collaboration room
function joinCollaborationRoom(roomId) {
    ws.send(JSON.stringify({
        type: 'join_room',
        data: { room_id: roomId }
    }));
}

// Share code changes with collaborators
function shareCodeChange(changes) {
    ws.send(JSON.stringify({
        type: 'code_change',
        data: {
            room_id: currentRoom,
            changes: changes,
            timestamp: Date.now()
        }
    }));
}

// Handle incoming code updates
ws.onmessage = function(event) {
    const message = JSON.parse(event.data);
    
    switch (message.type) {
        case 'code_update':
            applyRemoteChanges(message.data.changes);
            break;
        case 'user_joined':
            showUserJoined(message.data.user_id);
            break;
        case 'cursor_update':
            showRemoteCursor(message.data.user_id, message.data.position);
            break;
    }
};
```

## üîß Advanced Integration Examples

### 1. VS Code Extension Integration

```typescript
// vscode-extension/src/extension.ts
import * as vscode from 'vscode';
import axios from 'axios';

export function activate(context: vscode.ExtensionContext) {
    // Register AI code generation command
    let generateCommand = vscode.commands.registerCommand(
        'ai-coding-env.generateCode', 
        async () => {
            const editor = vscode.window.activeTextEditor;
            if (!editor) return;

            // Get user input
            const description = await vscode.window.showInputBox({
                prompt: 'Describe what you want to generate'
            });

            if (!description) return;

            // Call AI API
            try {
                const response = await axios.post('http://localhost:8000/api/ai/generate', {
                    description,
                    language: editor.document.languageId,
                    context: {
                        current_code: editor.document.getText(),
                        cursor_line: editor.selection.active.line
                    }
                });

                if (response.data.success) {
                    // Insert generated code at cursor position
                    await editor.edit(editBuilder => {
                        editBuilder.insert(editor.selection.active, response.data.content);
                    });
                    
                    vscode.window.showInformationMessage('Code generated successfully!');
                } else {
                    vscode.window.showErrorMessage(`Error: ${response.data.error}`);
                }
            } catch (error) {
                vscode.window.showErrorMessage(`Failed to generate code: ${error.message}`);
            }
        }
    );

    context.subscriptions.push(generateCommand);

    // Register code analysis command
    let analyzeCommand = vscode.commands.registerCommand(
        'ai-coding-env.analyzeCode',
        async () => {
            const editor = vscode.window.activeTextEditor;
            if (!editor) return;

            const code = editor.document.getText();
            if (!code.trim()) {
                vscode.window.showWarningMessage('No code to analyze');
                return;
            }

            try {
                const response = await axios.post('http://localhost:8000/api/ai/analyze', {
                    content: code,
                    language: editor.document.languageId,
                    analysis_type: 'comprehensive'
                });

                if (response.data.success) {
                    // Show analysis in new document
                    const doc = await vscode.workspace.openTextDocument({
                        content: response.data.content,
                        language: 'markdown'
                    });
                    await vscode.window.showTextDocument(doc);
                }
            } catch (error) {
                vscode.window.showErrorMessage(`Analysis failed: ${error.message}`);
            }
        }
    );

    context.subscriptions.push(analyzeCommand);
}
```

### 2. Slack Bot Integration

```python
# slack_bot/bot.py
import asyncio
import json
from slack_bolt.async_app import AsyncApp
from slack_bolt.adapter.socket_mode.async_handler import AsyncSocketModeHandler
import aiohttp

app = AsyncApp(token="your-bot-token")

@app.command("/generate-code")
async def generate_code_command(ack, respond, command):
    await ack()
    
    description = command['text']
    if not description:
        await respond("Please provide a description. Usage: `/generate-code create a REST API endpoint`")
        return
    
    try:
        # Call AI Coding Environment API
        async with aiohttp.ClientSession() as session:
            async with session.post(
                'http://localhost:8000/api/ai/generate',
                json={
                    'description': description,
                    'language': 'python',  # Default language
                    'context': {
                        'platform': 'slack',
                        'user': command['user_name']
                    }
                }
            ) as response:
                result = await response.json()
        
        if result['success']:
            # Format code for Slack
            code_block = f"```python\n{result['content']}\n```"
            await respond({
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"Here's your generated code:\n{code_block}"
                        }
                    },
                    {
                        "type": "context",
                        "elements": [
                            {
                                "type": "mrkdwn",
                                "text": f"Generated by {result['provider']} ‚Ä¢ Model: {result['model']}"
                            }
                        ]
                    }
                ]
            })
        else:
            await respond(f"Sorry, I couldn't generate code: {result['error']}")
            
    except Exception as e:
        await respond(f"Error connecting to AI service: {str(e)}")

@app.command("/analyze-code")
async def analyze_code_command(ack, respond, command):
    await ack()
    
    code = command['text']
    if not code:
        await respond("Please provide code to analyze. Usage: `/analyze-code def hello(): print('world')`")
        return
    
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(
                'http://localhost:8000/api/ai/analyze',
                json={
                    'content': code,
                    'language': 'python',
                    'analysis_type': 'comprehensive'
                }
            ) as response:
                result = await response.json()
        
        if result['success']:
            await respond({
                "blocks": [
                    {
                        "type": "section",
                        "text": {
                            "type": "mrkdwn",
                            "text": f"*Code Analysis Results:*\n```\n{result['content']}\n```"
                        }
                    }
                ]
            })
        else:
            await respond(f"Analysis failed: {result['error']}")
            
    except Exception as e:
        await respond(f"Error: {str(e)}")

# Start the bot
async def main():
    handler = AsyncSocketModeHandler(app, "your-app-token")
    await handler.start_async()

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. GitHub Actions Integration

```yaml
# .github/workflows/ai-code-review.yml
name: AI Code Review

on:
  pull_request:
    types: [opened, synchronize]

jobs:
  ai-review:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
      with:
        fetch-depth: 0

    - name: Get changed files
      id: changed-files
      uses: tj-actions/changed-files@v39
      with:
        files: |
          **/*.py
          **/*.js
          **/*.ts
          **/*.java

    - name: AI Code Review
      if: steps.changed-files.outputs.any_changed == 'true'
      run: |
        for file in ${{ steps.changed-files.outputs.all_changed_files }}; do
          echo "Analyzing $file..."
          
          # Read file content
          content=$(cat "$file")
          
          # Call AI analysis API
          response=$(curl -s -X POST \
            -H "Content-Type: application/json" \
            -d "{
              \"content\": \"$content\",
              \"language\": \"${file##*.}\",
              \"analysis_type\": \"security_and_quality\"
            }" \
            "${{ secrets.AI_CODING_ENV_URL }}/api/ai/analyze")
          
          # Parse response and add comment to PR
          if echo "$response" | jq -e '.success' > /dev/null; then
            analysis=$(echo "$response" | jq -r '.content')
            
            gh pr comment ${{ github.event.pull_request.number }} \
              --body "## AI Code Review for \`$file\`

$analysis

---
*Powered by AI-Assisted Coding Environment*"
          fi
        done
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

## üéì Educational Examples

### 1. Interactive Coding Tutorial

```python
# tutorial_generator.py
import asyncio
import json
from typing import List, Dict

class InteractiveTutorial:
    def __init__(self, api_base: str):
        self.api_base = api_base
        self.session = aiohttp.ClientSession()
        
    async def create_tutorial(self, topic: str, difficulty: str) -> Dict:
        """Generate an interactive coding tutorial"""
        
        prompt = f"""
        Create an interactive {difficulty} level tutorial for {topic}.
        Include:
        1. Step-by-step explanation
        2. Code examples with comments
        3. Practice exercises
        4. Common mistakes to avoid
        5. Progressive difficulty
        """
        
        response = await self.session.post(
            f"{self.api_base}/api/ai/generate",
            json={
                "description": prompt,
                "language": "python",
                "context": {
                    "type": "tutorial",
                    "topic": topic,
                    "difficulty": difficulty
                }
            }
        )
        
        return await response.json()
    
    async def validate_exercise_solution(self, exercise: str, solution: str) -> Dict:
        """Validate student's solution to an exercise"""
        
        prompt = f"""
        Exercise: {exercise}
        
        Student Solution:
        {solution}
        
        Please provide:
        1. Correctness assessment
        2. Code quality feedback
        3. Suggestions for improvement
        4. Alternative approaches
        """
        
        response = await self.session.post(
            f"{self.api_base}/api/ai/analyze",
            json={
                "content": solution,
                "language": "python",
                "analysis_type": "educational"
            }
        )
        
        return await response.json()

# Usage example
async def main():
    tutorial = InteractiveTutorial("http://localhost:8000")
    
    # Generate tutorial
    result = await tutorial.create_tutorial("recursion", "intermediate")
    print("Generated Tutorial:")
    print(result["content"])
    
    # Validate student solution
    exercise = "Write a recursive function to calculate factorial"
    student_solution = """
    def factorial(n):
        if n == 0:
            return 1
        return n * factorial(n - 1)
    """
    
    feedback = await tutorial.validate_exercise_solution(exercise, student_solution)
    print("\nFeedback:")
    print(feedback["content"])

if __name__ == "__main__":
    asyncio.run(main())
```

### 2. Code Mentorship Bot

```python
# mentorship_bot.py
class CodeMentorBot:
    def __init__(self, api_client):
        self.api = api_client
        self.conversation_history = []
    
    async def provide_guidance(self, code: str, question: str) -> str:
        """Provide mentorship guidance for code and questions"""
        
        context = {
            "role": "mentor",
            "conversation_history": self.conversation_history[-5:],  # Last 5 exchanges
            "code_context": code,
            "learning_objective": "understanding and improvement"
        }
        
        prompt = f"""
        As a coding mentor, help with this question about the following code:
        
        Code:
        {code}
        
        Question: {question}
        
        Provide:
        1. Clear explanation of concepts
        2. Step-by-step guidance
        3. Best practices
        4. Encouragement and motivation
        """
        
        response = await self.api.generate_code(
            description=prompt,
            context=context
        )
        
        # Store conversation history
        self.conversation_history.append({
            "question": question,
            "response": response.content,
            "code": code
        })
        
        return response.content

# Integration with Discord bot
import discord
from discord.ext import commands

class MentorshipCog(commands.Cog):
    def __init__(self, bot):
        self.bot = bot
        self.mentor = CodeMentorBot(ai_api_client)
        
    @commands.command(name='help-code')
    async def help_with_code(self, ctx, *, message):
        """Get help with your code"""
        
        # Extract code block if present
        code = ""
        question = message
        
        if "```" in message:
            parts = message.split("```")
            if len(parts) >= 3:
                code = parts[1]
                question = parts[0] + parts[2]
        
        try:
            guidance = await self.mentor.provide_guidance(code, question)
            
            # Split long responses
            if len(guidance) > 1900:
                chunks = [guidance[i:i+1900] for i in range(0, len(guidance), 1900)]
                for chunk in chunks:
                    await ctx.send(f"```\n{chunk}\n```")
            else:
                await ctx.send(f"```\n{guidance}\n```")
                
        except Exception as e:
            await ctx.send(f"Sorry, I couldn't help with that: {str(e)}")
```

## üè¢ Enterprise Use Cases

### 1. Automated Code Review System

```python
# enterprise/code_review_automation.py
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum

class ReviewSeverity(Enum):
    INFO = "info"
    WARNING = "warning"
    ERROR = "error"
    CRITICAL = "critical"

@dataclass
class CodeReviewComment:
    line: int
    message: str
    severity: ReviewSeverity
    suggestion: Optional[str] = None

class EnterpriseCodeReviewer:
    def __init__(self, ai_api_client, review_config: Dict):
        self.ai_client = ai_api_client
        self.config = review_config
        
    async def review_pull_request(self, pr_data: Dict) -> Dict:
        """Comprehensive PR review with AI assistance"""
        
        results = {
            "overall_score": 0,
            "files_reviewed": [],
            "security_issues": [],
            "performance_issues": [],
            "maintainability_score": 0,
            "recommendations": []
        }
        
        for file_change in pr_data["changed_files"]:
            file_review = await self.review_file(file_change)
            results["files_reviewed"].append(file_review)
            
        # Aggregate results
        results["overall_score"] = self.calculate_overall_score(results["files_reviewed"])
        results["security_issues"] = self.extract_security_issues(results["files_reviewed"])
        results["performance_issues"] = self.extract_performance_issues(results["files_reviewed"])
        
        return results
    
    async def review_file(self, file_change: Dict) -> Dict:
        """Review individual file changes"""
        
        analysis_prompt = f"""
        Perform a comprehensive code review for this {file_change['language']} file change:
        
        File: {file_change['filename']}
        Changes: {file_change['diff']}
        
        Analyze for:
        1. Security vulnerabilities
        2. Performance issues
        3. Code quality and maintainability
        4. Best practices adherence
        5. Potential bugs
        6. Documentation needs
        
        Provide specific line-by-line feedback with severity levels.
        """
        
        response = await self.ai_client.analyze_code(
            content=file_change["content"],
            language=file_change["language"],
            context={
                "type": "enterprise_review",
                "filename": file_change["filename"],
                "diff": file_change["diff"],
                "config": self.config
            }
        )
        
        return {
            "filename": file_change["filename"],
            "analysis": response.content,
            "provider": response.provider,
            "comments": self.parse_review_comments(response.content),
            "score": self.calculate_file_score(response.content)
        }
    
    def parse_review_comments(self, analysis: str) -> List[CodeReviewComment]:
        """Parse AI analysis into structured comments"""
        # Implementation to parse AI response into structured format
        comments = []
        
        # This would parse the AI response and extract specific issues
        # with line numbers, severity, and suggestions
        
        return comments
    
    async def generate_security_report(self, codebase_path: str) -> Dict:
        """Generate comprehensive security analysis report"""
        
        security_prompt = """
        Perform a security audit of this codebase focusing on:
        1. Input validation vulnerabilities
        2. Authentication/authorization flaws
        3. SQL injection possibilities
        4. XSS vulnerabilities
        5. Insecure dependencies
        6. Data exposure risks
        7. Cryptographic issues
        
        Provide detailed findings with OWASP classifications and remediation steps.
        """
        
        # Scan all files in codebase
        security_findings = []
        
        for file_path in self.scan_codebase(codebase_path):
            with open(file_path, 'r') as f:
                content = f.read()
            
            response = await self.ai_client.analyze_code(
                content=content,
                language=self.detect_language(file_path),
                context={
                    "type": "security_audit",
                    "focus": "vulnerability_detection"
                }
            )
            
            if "security" in response.content.lower():
                security_findings.append({
                    "file": file_path,
                    "findings": response.content,
                    "severity": self.extract_severity(response.content)
                })
        
        return {
            "total_files_scanned": len(list(self.scan_codebase(codebase_path))),
            "vulnerabilities_found": len(security_findings),
            "critical_issues": [f for f in security_findings if f["severity"] == "critical"],
            "detailed_findings": security_findings,
            "recommendations": await self.generate_security_recommendations(security_findings)
        }

# Integration with CI/CD pipeline
class CIPipelineIntegration:
    def __init__(self, reviewer: EnterpriseCodeReviewer):
        self.reviewer = reviewer
        
    async def quality_gate_check(self, pr_data: Dict) -> bool:
        """Determine if PR meets quality standards"""
        
        review_results = await self.reviewer.review_pull_request(pr_data)
        
        # Define quality gates
        quality_thresholds = {
            "overall_score": 7.0,  # Minimum score out of 10
            "critical_issues": 0,   # No critical issues allowed
            "security_issues": 2,   # Max 2 minor security issues
        }
        
        # Check against thresholds
        passes_gate = (
            review_results["overall_score"] >= quality_thresholds["overall_score"] and
            len([i for i in review_results["security_issues"] if i["severity"] == "critical"]) <= quality_thresholds["critical_issues"] and
            len(review_results["security_issues"]) <= quality_thresholds["security_issues"]
        )
        
        return passes_gate, review_results

# Usage in Jenkins/GitHub Actions
async def ci_integration_example():
    # Initialize components
    ai_client = AIClient()
    reviewer = EnterpriseCodeReviewer(ai_client, enterprise_config)
    ci_integration = CIPipelineIntegration(reviewer)
    
    # Simulate PR data
    pr_data = {
        "id": "123",
        "changed_files": [
            {
                "filename": "src/auth.py",
                "content": "...",
                "language": "python",
                "diff": "..."
            }
        ]
    }
    
    # Run quality gate check
    passes, results = await ci_integration.quality_gate_check(pr_data)
    
    if passes:
        print("‚úÖ PR passes quality gate")
        return 0  # Exit code for CI success
    else:
        print("‚ùå PR fails quality gate")
        print(json.dumps(results, indent=2))
        return 1  # Exit code for CI failure
```

### 2. Development Team Analytics

```python
# analytics/team_productivity.py
class DevelopmentAnalytics:
    def __init__(self, ai_client, db_client):
        self.ai_client = ai_client
        self.db = db_client
        
    async def analyze_team_coding_patterns(self, team_id: str, period: str) -> Dict:
        """Analyze team coding patterns and productivity"""
        
        # Gather team coding data
        coding_sessions = await self.db.get_team_sessions(team_id, period)
        
        analysis_data = {
            "total_sessions": len(coding_sessions),
            "languages_used": self.extract_languages(coding_sessions),
            "ai_usage_patterns": self.analyze_ai_usage(coding_sessions),
            "collaboration_metrics": self.calculate_collaboration_metrics(coding_sessions),
            "productivity_trends": self.calculate_productivity_trends(coding_sessions)
        }
        
        # AI-powered insights
        insights_prompt = f"""
        Analyze this development team's coding patterns and provide insights:
        
        Team Data:
        {json.dumps(analysis_data, indent=2)}
        
        Provide:
        1. Productivity insights and trends
        2. Skill development recommendations
        3. Process improvement suggestions
        4. Tool usage optimization
        5. Team collaboration enhancement tips
        """
        
        ai_response = await self.ai_client.analyze_code(
            content=insights_prompt,
            language="analysis",
            context={"type": "team_analytics"}
        )
        
        return {
            **analysis_data,
            "ai_insights": ai_response.content,
            "recommendations": self.parse_recommendations(ai_response.content)
        }
    
    async def generate_individual_developer_report(self, developer_id: str) -> Dict:
        """Generate personalized developer improvement report"""
        
        developer_data = await self.db.get_developer_data(developer_id)
        
        report_prompt = f"""
        Generate a personalized development report for this developer:
        
        Coding Statistics:
        - Languages: {developer_data['languages']}
        - Lines of code: {developer_data['loc']}
        - AI assistance usage: {developer_data['ai_usage']}
        - Code quality scores: {developer_data['quality_scores']}
        - Collaboration frequency: {developer_data['collaboration']}
        
        Provide:
        1. Strengths and areas of expertise
        2. Skill gaps and learning opportunities
        3. Personalized learning path
        4. Goal recommendations
        5. Recognition achievements
        """
        
        response = await self.ai_client.generate_code(
            description=report_prompt,
            context={"type": "developer_report", "personalized": True}
        )
        
        return {
            "developer_id": developer_id,
            "report": response.content,
            "learning_recommendations": self.extract_learning_paths(response.content),
            "skill_assessment": self.assess_skill_levels(developer_data)
        }
```

## üß™ Testing and Quality Assurance Examples

### 1. Automated Test Generation

```python
# testing/test_generator.py
class AITestGenerator:
    def __init__(self, ai_client):
        self.ai_client = ai_client
        
    async def generate_comprehensive_tests(self, source_code: str, language: str) -> Dict:
        """Generate comprehensive test suite for given code"""
        
        test_prompt = f"""
        Generate a comprehensive test suite for this {language} code:
        
        {source_code}
        
        Include:
        1. Unit tests for all functions/methods
        2. Edge case testing
        3. Error handling tests
        4. Integration tests where applicable
        5. Performance tests for critical functions
        6. Mock usage for external dependencies
        7. Parameterized tests for multiple scenarios
        
        Use appropriate testing framework and follow best practices.
        """
        
        response = await self.ai_client.generate_code(
            description=test_prompt,
            language=language,
            context={
                "type": "test_generation",
                "comprehensive": True,
                "source_code": source_code
            }
        )
        
        return {
            "test_code": response.content,
            "framework": self.detect_test_framework(response.content, language),
            "coverage_analysis": await self.analyze_test_coverage(source_code, response.content),
            "test_categories": self.categorize_tests(response.content)
        }
    
    async def generate_property_based_tests(self, function_signature: str, language: str) -> str:
        """Generate property-based tests using Hypothesis or similar"""
        
        property_prompt = f"""
        Generate property-based tests for this function:
        {function_signature}
        
        Use {language} property testing framework (Hypothesis for Python, etc.)
        Focus on:
        1. Input property invariants
        2. Output property verification
        3. Relationship testing
        4. Metamorphic testing
        5. Statistical testing where relevant
        """
        
        response = await self.ai_client.generate_code(
            description=property_prompt,
            language=language,
            context={"type": "property_testing"}
        )
        
        return response.content

# Example usage
async def test_generation_example():
    generator = AITestGenerator(ai_client)
    
    source_code = """
    def binary_search(arr, target):
        left, right = 0, len(arr) - 1
        
        while left <= right:
            mid = (left + right) // 2
            if arr[mid] == target:
                return mid
            elif arr[mid] < target:
                left = mid + 1
            else:
                right = mid - 1
        
        return -1
    """
    
    test_suite = await generator.generate_comprehensive_tests(source_code, "python")
    print("Generated Test Suite:")
    print(test_suite["test_code"])
    
    # Generate property-based tests
    property_tests = await generator.generate_property_based_tests(
        "def binary_search(arr: List[int], target: int) -> int", 
        "python"
    )
    print("\nProperty-Based Tests:")
    print(property_tests)
```

## üîß DevOps and Infrastructure Examples

### 1. Infrastructure as Code Generation

```python
# devops/infrastructure_generator.py
class InfrastructureGenerator:
    def __init__(self, ai_client):
        self.ai_client = ai_client
        
    async def generate_terraform_config(self, requirements: Dict) -> str:
        """Generate Terraform configuration based on requirements"""
        
        terraform_prompt = f"""
        Generate Terraform configuration for the following requirements:
        
        Platform: {requirements.get('platform', 'AWS')}
        Application Type: {requirements.get('app_type', 'web_application')}
        Scaling Requirements: {requirements.get('scaling', 'moderate')}
        Database: {requirements.get('database', 'postgresql')}
        Caching: {requirements.get('caching', 'redis')}
        Load Balancing: {requirements.get('load_balancer', True)}
        SSL/TLS: {requirements.get('ssl', True)}
        Monitoring: {requirements.get('monitoring', True)}
        Backup Strategy: {requirements.get('backup', 'daily')}
        
        Include:
        1. VPC and networking setup
        2. Security groups and IAM roles
        3. Auto-scaling configuration
        4. Database setup with backup
        5. Load balancer configuration
        6. SSL certificate management
        7. Monitoring and logging setup
        8. Cost optimization best practices
        """
        
        response = await self.ai_client.generate_code(
            description=terraform_prompt,
            language="hcl",
            context={
                "type": "infrastructure",
                "platform": requirements.get('platform'),
                "requirements": requirements
            }
        )
        
        return response.content
    
    async def generate_kubernetes_manifests(self, app_config: Dict) -> Dict:
        """Generate Kubernetes deployment manifests"""
        
        k8s_prompt = f"""
        Generate Kubernetes manifests for this application:
        
        Application: {app_config['name']}
        Image: {app_config['image']}
        Port: {app_config.get('port', 8000)}
        Replicas: {app_config.get('replicas', 3)}
        Resources: {app_config.get('resources', 'medium')}
        Environment: {app_config.get('environment', 'production')}
        Database: {app_config.get('database', False)}
        Storage: {app_config.get('storage', False)}
        
        Include:
        1. Deployment manifest
        2. Service configuration
        3. Ingress setup
        4. ConfigMap and Secrets
        5. HorizontalPodAutoscaler
        6. NetworkPolicy for security
        7. ServiceMonitor for monitoring
        8. PersistentVolume if storage needed
        """
        
        response = await self.ai_client.generate_code(
            description=k8s_prompt,
            language="yaml",
            context={
                "type": "kubernetes",
                "app_config": app_config
            }
        )
        
        return {
            "manifests": response.content,
            "deployment_guide": await self.generate_deployment_guide(app_config),
            "monitoring_setup": await self.generate_monitoring_config(app_config)
        }
    
    async def generate_ci_cd_pipeline(self, project_config: Dict) -> str:
        """Generate CI/CD pipeline configuration"""
        
        pipeline_prompt = f"""
        Generate a complete CI/CD pipeline for:
        
        Project Type: {project_config['type']}
        Language: {project_config['language']}
        Testing Framework: {project_config.get('testing_framework')}
        Deployment Target: {project_config.get('deployment_target', 'kubernetes')}
        Security Scanning: {project_config.get('security_scanning', True)}
        Code Quality Gates: {project_config.get('quality_gates', True)}
        
        Include stages for:
        1. Code checkout and setup
        2. Dependency management
        3. Testing (unit, integration, e2e)
        4. Security scanning
        5. Code quality analysis
        6. Build and package
        7. Deployment to staging
        8. Production deployment with approval
        9. Rollback mechanisms
        10. Notifications
        """
        
        response = await self.ai_client.generate_code(
            description=pipeline_prompt,
            language="yaml",
            context={
                "type": "ci_cd_pipeline",
                "project_config": project_config
            }
        )
        
        return response.content

# Usage example
async def infrastructure_example():
    generator = InfrastructureGenerator(ai_client)
    
    # Generate Terraform for web application
    requirements = {
        "platform": "AWS",
        "app_type": "web_application",
        "scaling": "high",
        "database": "postgresql",
        "caching": "redis",
        "load_balancer": True,
        "ssl": True,
        "monitoring": True,
        "backup": "daily"
    }
    
    terraform_config = await generator.generate_terraform_config(requirements)
    print("Terraform Configuration:")
    print(terraform_config)
    
    # Generate Kubernetes manifests
    app_config = {
        "name": "ai-coding-env",
        "image": "ai-coding-env:latest",
        "port": 8000,
        "replicas": 3,
        "resources": "medium",
        "environment": "production",
        "database": True,
        "storage": True
    }
    
    k8s_manifests = await generator.generate_kubernetes_manifests(app_config)
    print("\nKubernetes Manifests:")
    print(k8s_manifests["manifests"])
```

---

## üîó Additional Resources

- **Live Demos**: Visit our [demo environment](https://demo.ai-coding-env.com)
- **Video Tutorials**: [YouTube Playlist](https://youtube.com/playlist?list=...)
- **Community Examples**: [GitHub Discussions](https://github.com/karimosman89/AI-Assisted-Coding-Env/discussions)
- **Enterprise Solutions**: Contact us for custom enterprise examples

## ü§ù Contributing Examples

Have a great example to share? We'd love to include it!

1. Fork the repository
2. Add your example to the appropriate directory
3. Include comprehensive documentation
4. Test your example thoroughly
5. Submit a pull request

**Example Format:**
- Clear description of use case
- Step-by-step setup instructions
- Complete, working code
- Expected outputs/results
- Troubleshooting section

---

These examples demonstrate the versatility and power of the AI-Assisted Coding Environment. Whether you're building simple scripts or complex enterprise systems, the platform adapts to your needs with intelligent AI assistance.